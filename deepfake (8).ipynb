{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10869235,"sourceType":"datasetVersion","datasetId":6752585}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport csv\nfrom tqdm import tqdm\nimport time\nimport torchvision.transforms as transforms\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:27.367530Z","iopub.execute_input":"2025-03-07T16:31:27.367856Z","iopub.status.idle":"2025-03-07T16:31:33.666659Z","shell.execute_reply.started":"2025-03-07T16:31:27.367825Z","shell.execute_reply":"2025-03-07T16:31:33.665952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:33.667619Z","iopub.execute_input":"2025-03-07T16:31:33.668019Z","iopub.status.idle":"2025-03-07T16:31:33.734208Z","shell.execute_reply.started":"2025-03-07T16:31:33.667996Z","shell.execute_reply":"2025-03-07T16:31:33.733096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class paths:\n    fake_dir = '/kaggle/input/deep-fake-dataset/SDFVD/videos_fake/'\n    real_dir = '/kaggle/input/deep-fake-dataset/SDFVD/videos_real/'\n\n    data_dict = {}\n\n    batch_size = 2\n    learning_rate = 1e-3\n    #epochs = 50","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:33.735540Z","iopub.execute_input":"2025-03-07T16:31:33.735805Z","iopub.status.idle":"2025-03-07T16:31:33.751364Z","shell.execute_reply.started":"2025-03-07T16:31:33.735782Z","shell.execute_reply":"2025-03-07T16:31:33.750601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fake_paths  = [os.path.join(paths.fake_dir, path) for path in os.listdir(paths.fake_dir)]\nreal_paths  = [os.path.join(paths.real_dir, path) for path in os.listdir(paths.real_dir)]\n\npaths.data_dict.update({paths: 0 for paths in fake_paths })\npaths.data_dict.update({paths: 1 for paths in  real_paths})\n\nprint(f'Total number of fake videos :{len(fake_paths)}')\nprint(f'Total number of real videos :{len(real_paths)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:36.772762Z","iopub.execute_input":"2025-03-07T16:31:36.773061Z","iopub.status.idle":"2025-03-07T16:31:36.797039Z","shell.execute_reply.started":"2025-03-07T16:31:36.773039Z","shell.execute_reply":"2025-03-07T16:31:36.796242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for path, label in list(paths.data_dict.items())[:5]:\n    print(f'Path: {path},  Label: {label}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:37.175959Z","iopub.execute_input":"2025-03-07T16:31:37.176295Z","iopub.status.idle":"2025-03-07T16:31:37.181241Z","shell.execute_reply.started":"2025-03-07T16:31:37.176264Z","shell.execute_reply":"2025-03-07T16:31:37.180036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def crop_frame(frame):\n    y,x = frame.shape[0:2]\n    min_val = min(x,y)\n    start_x = ( x//2 ) - ( min_val//2 )\n    start_y = ( y//2 ) - ( min_val//2 )\n\n    return frame[ start_y : start_y + min_val , start_x : start_x + min_val]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:37.521691Z","iopub.execute_input":"2025-03-07T16:31:37.521982Z","iopub.status.idle":"2025-03-07T16:31:37.526298Z","shell.execute_reply.started":"2025-03-07T16:31:37.521958Z","shell.execute_reply":"2025-03-07T16:31:37.525486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cap = cv2.VideoCapture(paths.fake_dir + 'vs11.mp4')\nret, frame = cap.read()\nif ret:\n    frame = crop_frame(frame)\n    frame = cv2.resize(frame, (299,299))   \n    frame = frame[:, :, (2,1,0)]\n    \n    plt.imshow(frame)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:39.233008Z","iopub.execute_input":"2025-03-07T16:31:39.233337Z","iopub.status.idle":"2025-03-07T16:31:39.576026Z","shell.execute_reply.started":"2025-03-07T16:31:39.233310Z","shell.execute_reply":"2025-03-07T16:31:39.575255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_frames(frames, max_frames):\n    \n    if len(frames) >= max_frames:\n        return frames[:max_frames]\n        \n    return frames + [frames[-1]] * (max_frames - len(frames))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:39.577246Z","iopub.execute_input":"2025-03-07T16:31:39.577610Z","iopub.status.idle":"2025-03-07T16:31:39.581832Z","shell.execute_reply.started":"2025-03-07T16:31:39.577579Z","shell.execute_reply":"2025-03-07T16:31:39.581069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import models\nfrom torchvision.models import Inception_V3_Weights\nfrom torchsummary import summary\n\nfeature_extractor = models.inception_v3(weights = Inception_V3_Weights.DEFAULT).to(device)\nfeature_extractor.fc = torch.nn.Identity()\nfeature_extractor.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:39.850731Z","iopub.execute_input":"2025-03-07T16:31:39.851019Z","iopub.status.idle":"2025-03-07T16:31:41.956158Z","shell.execute_reply.started":"2025-03-07T16:31:39.850995Z","shell.execute_reply":"2025-03-07T16:31:41.955283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:41.957312Z","iopub.execute_input":"2025-03-07T16:31:41.957593Z","iopub.status.idle":"2025-03-07T16:31:41.961421Z","shell.execute_reply.started":"2025-03-07T16:31:41.957571Z","shell.execute_reply":"2025-03-07T16:31:41.960675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DeepfakeDataset(Dataset):\n    def __init__(self, paths, labels):\n        self.paths = paths\n        self.labels = labels\n      \n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self,idx):\n        video_path = self.paths[idx]\n        frames = []\n        \n        cap = cv2.VideoCapture(video_path)\n        \n        while True:\n            ret, frame = cap.read()\n\n            if not ret:\n                break\n                \n            frame = crop_frame(frame) \n            frame = cv2.resize(frame, (299,299))   \n            frame = frame[:, :, (2,1,0)]\n            frame = transform(frame)\n            frames.append(frame)\n            \n        cap.release()\n\n        frames = process_frames(frames, max_frames = 64)\n        frames = np.array(frames)\n\n        frames = torch.tensor(frames,dtype=torch.float32).to(device)\n        \n        features = feature_extractor(frames)\n\n        return  features, torch.tensor(self.labels[idx]).to(device)\n       ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:41.962776Z","iopub.execute_input":"2025-03-07T16:31:41.963069Z","iopub.status.idle":"2025-03-07T16:31:41.987472Z","shell.execute_reply.started":"2025-03-07T16:31:41.963035Z","shell.execute_reply":"2025-03-07T16:31:41.986485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"videos = list(paths.data_dict.keys())\nlabels = list(paths.data_dict.values())\nprint(len(videos))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:42.674244Z","iopub.execute_input":"2025-03-07T16:31:42.674580Z","iopub.status.idle":"2025-03-07T16:31:42.679130Z","shell.execute_reply.started":"2025-03-07T16:31:42.674549Z","shell.execute_reply":"2025-03-07T16:31:42.678312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Xtrain, Xtest, Ytrain, Ytest = train_test_split(videos, labels, test_size = 0.2, stratify=labels, random_state = 42, shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:43.046918Z","iopub.execute_input":"2025-03-07T16:31:43.047263Z","iopub.status.idle":"2025-03-07T16:31:43.053244Z","shell.execute_reply.started":"2025-03-07T16:31:43.047233Z","shell.execute_reply":"2025-03-07T16:31:43.052552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset    = DeepfakeDataset(Xtrain, Ytrain)\ntrain_dataloader = DataLoader(train_dataset , batch_size = paths.batch_size , shuffle = True)\n\ntest_dataset = DeepfakeDataset(Xtest, Ytest)\ntest_dataloader = DataLoader(test_dataset , batch_size = paths.batch_size , shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:43.398859Z","iopub.execute_input":"2025-03-07T16:31:43.399150Z","iopub.status.idle":"2025-03-07T16:31:43.403803Z","shell.execute_reply.started":"2025-03-07T16:31:43.399127Z","shell.execute_reply":"2025-03-07T16:31:43.402985Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DeepfakeGru(nn.Module):\n    def __init__(self, input_size=2048, hidden_size=256, num_layers=2, num_classes=1):\n        super(DeepfakeGru, self).__init__()\n        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=0.5)  \n        self.batchnorm1 = nn.BatchNorm1d(hidden_size) \n        self.dropout = nn.Dropout(p=0.5)  \n        self.fc = nn.Linear(hidden_size, num_classes)\n        self.batchnorm2 = nn.BatchNorm1d(num_classes)  \n\n    def forward(self, x):\n        if isinstance(x, tuple):\n            x = x[0]\n\n        _, hidden = self.gru(x)\n        hidden = self.batchnorm1(hidden[-1])  \n        hidden = self.dropout(hidden)  \n        \n        out = self.fc(hidden)\n        out = self.batchnorm2(out)  \n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:45.614805Z","iopub.execute_input":"2025-03-07T16:31:45.615108Z","iopub.status.idle":"2025-03-07T16:31:45.620875Z","shell.execute_reply.started":"2025-03-07T16:31:45.615083Z","shell.execute_reply":"2025-03-07T16:31:45.620051Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = DeepfakeGru()\n\ncriterion = nn.BCEWithLogitsLoss()\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:48.199705Z","iopub.execute_input":"2025-03-07T16:31:48.199990Z","iopub.status.idle":"2025-03-07T16:31:48.220154Z","shell.execute_reply.started":"2025-03-07T16:31:48.199967Z","shell.execute_reply":"2025-03-07T16:31:48.219543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def perform_validation(model, test_dataloader, device):\n    model.eval()  \n    val_loss, val_accuracy, val_precision, val_recall = 0, 0, 0, 0\n\n    #val_iterator = tqdm(test_dataloader, leave=False)\n    with torch.no_grad():\n        for inputs, labels in test_dataloader:\n            inputs = inputs.to(device)\n            labels = labels.float().unsqueeze(1).to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            \n            predictions = torch.sigmoid(outputs) > 0.5\n\n            \n            labels_np = labels.cpu().numpy()\n            predictions_np = predictions.cpu().numpy()\n\n            \n            accuracy = accuracy_score(labels_np, predictions_np)\n            precision = precision_score(labels_np, predictions_np, zero_division=1)\n            recall = recall_score(labels_np, predictions_np, zero_division=1)\n\n            val_loss += loss.item()\n            val_accuracy += accuracy\n            val_precision += precision\n            val_recall += recall\n\n    num_batches = len(test_dataloader)\n    return (\n        val_loss / num_batches,\n        val_accuracy / num_batches,\n        val_precision / num_batches,\n        val_recall / num_batches\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:52.356233Z","iopub.execute_input":"2025-03-07T16:31:52.356515Z","iopub.status.idle":"2025-03-07T16:31:52.362262Z","shell.execute_reply.started":"2025-03-07T16:31:52.356493Z","shell.execute_reply":"2025-03-07T16:31:52.361475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nimport csv\nimport torch\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\nmodel.to(device)\n\nepochs = 50\nbest_accuracy = 0.0\ntotal_training_time = 0.0\nlog_file = \"Deepfake_299.csv\"\n\nlog_fields = [\n    \"epoch\", \"time\", \"train_loss\", \"val_loss\",\n    \"accuracy_train\", \"accuracy_val\",\n    \"precision_train\", \"precision_val\",\n    \"recall_train\", \"recall_val\"\n]\n\n# Create CSV file with headers\nwith open(log_file, 'w', newline='', encoding='utf-8') as csvfile:\n    writer = csv.DictWriter(csvfile, fieldnames=log_fields)\n    writer.writeheader()\n\nfor epoch in range(epochs):\n    model.train()\n    start_time = time.time()\n\n    train_loss, total_train_accuracy, total_train_precision, total_train_recall = 0.0, 0.0, 0.0, 0.0\n    val_loss, val_accuracy, val_precision, val_recall = 0.0, 0.0, 0.0, 0.0\n\n    with tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\") as train_iterator:\n        for i, (inputs, labels) in enumerate(train_iterator):\n            inputs, labels = inputs.to(device), labels.float().unsqueeze(1).to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n           \n            predictions = (torch.sigmoid(outputs) > 0.5).detach().cpu().numpy()\n            labels_np = labels.cpu().numpy()\n\n            train_accuracy = accuracy_score(labels_np, predictions)\n            train_precision = precision_score(labels_np, predictions, zero_division=0)\n            train_recall = recall_score(labels_np, predictions, zero_division=0)\n\n            train_loss += loss.item()\n            total_train_accuracy += train_accuracy\n            total_train_precision += train_precision\n            total_train_recall += train_recall\n\n           \n            if i == len(train_dataloader) - 1:\n                val_loss, val_accuracy, val_precision, val_recall = perform_validation(model, test_dataloader, device)\n                scheduler.step(val_loss)\n\n                if val_accuracy > best_accuracy:\n                    torch.save(model.state_dict(), 'deepfake_299.pt')\n                    best_accuracy = val_accuracy\n\n            \n            train_iterator.set_postfix({\n                'loss': f\"{train_loss / (i + 1):.4f}\",\n                'accuracy': f\"{total_train_accuracy / (i + 1):.4f}\",\n                'precision': f\"{total_train_precision / (i + 1):.4f}\",\n                'recall': f\"{total_train_recall / (i + 1):.4f}\",\n                'val_loss': f\"{val_loss:.4f}\",\n                'val_acc': f\"{val_accuracy:.4f}\",\n                'val_prec': f\"{val_precision:.4f}\",\n                'val_rec': f\"{val_recall:.4f}\"\n            })\n\n    epoch_time = time.time() - start_time\n    total_training_time += epoch_time\n\n \n    with open(log_file, 'a', newline='', encoding='utf-8') as csvfile:\n        writer = csv.DictWriter(csvfile, fieldnames=log_fields)\n        writer.writerow({\n            \"epoch\": epoch + 1,\n            \"time\": round(epoch_time, 4),\n            \"train_loss\": round(train_loss / len(train_dataloader), 4),\n            \"val_loss\": round(val_loss, 4),\n            \"accuracy_train\": round(total_train_accuracy / len(train_dataloader), 4),\n            \"accuracy_val\": round(val_accuracy, 4),\n            \"precision_train\": round(total_train_precision / len(train_dataloader), 4),\n            \"precision_val\": round(val_precision, 4),\n            \"recall_train\": round(total_train_recall / len(train_dataloader), 4),\n            \"recall_val\": round(val_recall, 4)\n        })\n\nprint(f\"Training Complete in {total_training_time:.2f}s with {total_training_time / epochs:.2f}s per epoch.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:31:54.253863Z","iopub.execute_input":"2025-03-07T16:31:54.254153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}